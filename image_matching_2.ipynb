{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_th = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "img_color_1 = cv2.imread('spy1.jpg')\n",
    "img_color_2 = cv2.imread('spy2.jpg')\n",
    "\n",
    "\n",
    "img1 = cv2.cvtColor(img_color_1, cv2.COLOR_BGR2YCrCb)[:,:,0]\n",
    "img2 = cv2.cvtColor(img_color_2, cv2.COLOR_BGR2YCrCb)[:,:,0]\n",
    "\n",
    "# Create SIFT detector\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints1, descriptors1 = sift.detectAndCompute(img1, None)\n",
    "keypoints2, descriptors2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "# Create a matcher\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "# Match descriptors\n",
    "matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "# Apply ratio test to filter good matches\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < ratio_th * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "if len(good_matches) > 0:\n",
    "    # Draw matches on images\n",
    "    img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    # Display the result\n",
    "    win = cv2.namedWindow('Initially found matches', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('Initially found matches', img_matches)\n",
    "else:\n",
    "    print(\"Not eough good matches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.07062913e+00  1.64185216e-01  1.17178225e+02]\n",
      " [-6.89350664e-01  3.06729720e+00 -2.44633753e+02]\n",
      " [-9.98968244e-04  2.48346570e-03  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Extract matched keypoints\n",
    "src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "# Use RANSAC to estimate the transformation matrix\n",
    "transformation_matrix, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "print(transformation_matrix)\n",
    "# Draw matches on images excluding outliers\n",
    "good_matches_outlier_removed = np.array(good_matches)[mask.ravel() == 1]\n",
    "img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2, \n",
    "                              good_matches_outlier_removed, \n",
    "                              None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "win = cv2.namedWindow('Matches after reprojection iterations', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('Matches after reprojection iterations', img_matches)\n",
    "\n",
    "\n",
    "# Apply the transformation to image1\n",
    "registered_img_color_1 = cv2.warpPerspective(img_color_1, transformation_matrix, (img_color_2.shape[1], img_color_2.shape[0]))\n",
    "\n",
    "# Display the results\n",
    "cv2.imshow('Registered Image 1', registered_img_color_1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Croping based on most external keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902 (21, 2) 370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([155, 161]), array([364, 346]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.array([kps_des_list[i]['kps'][m.queryIdx].pt for m in masked_matches_list[i]], dtype='float')\n",
    "\n",
    "good_kps2_pt = np.array([keypoints2[m.trainIdx].pt for m in good_matches_outlier_removed])\n",
    "print(len(keypoints2), good_kps2_pt.shape, len(good_matches))\n",
    "bbox = (np.array([np.min(good_kps2_pt[:,1]), np.min(good_kps2_pt[:,0])], dtype=int),\n",
    "        np.array([np.max(good_kps2_pt[:,1]), np.max(good_kps2_pt[:,0])], dtype=int)) # (x, y) = (column, row)\n",
    "bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display cropped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_img_color_1_bbox = cv2.rectangle(registered_img_color_1.copy(), bbox[0][::-1], bbox[1][::-1], color=(0, 255, 0))\n",
    "img_color_2_bbox = cv2.rectangle(img_color_2.copy(), bbox[0][::-1], bbox[1][::-1], color=(0, 255, 0))\n",
    "# cv2.imshow('Registered Image 1', registered_img_color_1_bbox)\n",
    "# cv2.imshow('Original Image 2', img_color_2_bbox)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "registered_img_color_1_cropped = registered_img_color_1_bbox[bbox[0][0]:bbox[1][0], bbox[0][1]:bbox[1][1], :]\n",
    "img_color_2_cropped = img_color_2_bbox[bbox[0][0]:bbox[1][0], bbox[0][1]:bbox[1][1], :]\n",
    "cv2.imshow('Registered Image 1', registered_img_color_1_cropped)\n",
    "cv2.imshow('Original Image 2', img_color_2_cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to luminance-chrominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1_comp = cv2.cvtColor(registered_img_color_1_cropped, cv2.COLOR_BGR2YCrCb).astype(float)/255\n",
    "im2_comp = cv2.cvtColor(img_color_2_cropped, cv2.COLOR_BGR2YCrCb).astype(float)/255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation in blue (e.g. spyder logo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimation_factor = 4\n",
    "corr_blue = (im1_comp[::decimation_factor,::decimation_factor,2]-0.5)*(im2_comp[::decimation_factor,::decimation_factor,2]-0.5)\n",
    "corr_blue += np.min(corr_blue)\n",
    "corr_blue /= np.max(corr_blue)\n",
    "cv2.namedWindow('Image 1', cv2.WINDOW_FREERATIO)\n",
    "cv2.namedWindow('Image 2', cv2.WINDOW_FREERATIO)\n",
    "cv2.namedWindow('Chrome blue correlation', cv2.WINDOW_FREERATIO)\n",
    "\n",
    "cv2.imshow('Image 1', im1_comp[:,:,2])\n",
    "cv2.imshow('Image 2', im2_comp[:,:,2])\n",
    "cv2.imshow('Chrome blue correlation', corr_blue)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation in luminance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_Y = (im1_comp[::decimation_factor,::decimation_factor,0]-0.5)*(im2_comp[::decimation_factor,::decimation_factor,0]-0.5)\n",
    "corr_Y += np.min(corr_Y)\n",
    "corr_Y /= np.max(corr_Y)\n",
    "cv2.namedWindow('Image 1', cv2.WINDOW_FREERATIO)\n",
    "cv2.namedWindow('Image 2', cv2.WINDOW_FREERATIO)\n",
    "cv2.namedWindow('Y correlation', cv2.WINDOW_FREERATIO)\n",
    "\n",
    "cv2.imshow('Image 1', im1_comp[:,:,0])\n",
    "cv2.imshow('Image 2', im2_comp[:,:,0])\n",
    "cv2.imshow('Y correlation', corr_Y)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation in red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_red = (im1_comp[::decimation_factor,::decimation_factor,1]-0.5)*(im2_comp[::decimation_factor,::decimation_factor,1]-0.5)\n",
    "corr_red += np.min(corr_red)\n",
    "corr_red /= np.max(corr_red)\n",
    "cv2.namedWindow('Image 1', cv2.WINDOW_FREERATIO)\n",
    "cv2.namedWindow('Image 2', cv2.WINDOW_FREERATIO)\n",
    "cv2.namedWindow('Chrome red correlation', cv2.WINDOW_FREERATIO)\n",
    "\n",
    "cv2.imshow('Image 1', im1_comp[:,:,1])\n",
    "cv2.imshow('Image 2', im2_comp[:,:,1])\n",
    "cv2.imshow('Chrome red correlation', corr_red)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
