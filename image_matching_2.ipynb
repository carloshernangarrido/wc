{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_th = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "img_color_1 = cv2.imread('spy2.jpg')\n",
    "img_color_2 = cv2.imread('spy1.jpg')\n",
    "\n",
    "\n",
    "img1 = cv2.cvtColor(img_color_1, cv2.COLOR_BGR2YCrCb)[:,:,0]\n",
    "img2 = cv2.cvtColor(img_color_2, cv2.COLOR_BGR2YCrCb)[:,:,0]\n",
    "\n",
    "# Create SIFT detector\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints1, descriptors1 = sift.detectAndCompute(img1, None)\n",
    "keypoints2, descriptors2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "# Create a matcher\n",
    "bf = cv2.FlannBasedMatcher()\n",
    "\n",
    "# Match descriptors\n",
    "matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "# Apply ratio test to filter good matches\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < ratio_th * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "# Draw matches on images\n",
    "img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "\n",
    "# Display the result\n",
    "win = cv2.namedWindow('Initially found matches', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('Initially found matches', img_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract matched keypoints\n",
    "src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "# Use RANSAC to estimate the transformation matrix\n",
    "transformation_matrix, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "# Draw matches on images excluding outliers\n",
    "img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2, \n",
    "                              np.array(good_matches)[mask.ravel() == 1], \n",
    "                              None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "win = cv2.namedWindow('Matches after reprojection iterations', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('Matches after reprojection iterations', img_matches)\n",
    "\n",
    "\n",
    "# Apply the transformation to image1\n",
    "registered_image = cv2.warpPerspective(img_color_1, transformation_matrix, (img_color_2.shape[1], img_color_2.shape[0]))\n",
    "\n",
    "# Display the results\n",
    "cv2.imshow('Image 1', img_color_1)\n",
    "cv2.imshow('Image 2', img_color_2)\n",
    "cv2.imshow('Registered Image 1', registered_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
