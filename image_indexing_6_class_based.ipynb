{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import os\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_images = r'C:\\Fotos y videos\\test bovw'\n",
    "path_images = r'C:\\TRABAJO\\Willdom\\Sr Machine Learning Engineer\\Challenge'\n",
    "working_resolution = [512,512]\n",
    "vocabulary_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageRetriever:\n",
    "    def __init__(self, working_resolution: list = None, vocabulary_size: int = 64) -> None:\n",
    "        self.working_resolution = [512, 512] if working_resolution is None else working_resolution\n",
    "        assert len(self.working_resolution) == 2\n",
    "        assert isinstance(vocabulary_size, int) and vocabulary_size > 2\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "\n",
    "        self.images = None\n",
    "        self.visual_dictionary = None\n",
    "        self.descriptors_by_image = None\n",
    "        self.visual_words = None\n",
    "        self.word_classifier = None\n",
    "        self.words_by_image = None\n",
    "        self.global_descriptor_by_image = None\n",
    "        self.global_descriptors = None\n",
    "\n",
    "    def fit(self, folder_path: str):\n",
    "        # Helper functions\n",
    "        def load_images_from_folder(folder: str, resolution: list) -> list:\n",
    "            images = {}\n",
    "            for filename in os.listdir(folder):\n",
    "                if filename.split('.')[-1] == 'jpg':\n",
    "                    path = os.path.join(folder, filename)\n",
    "                    img = cv2.imread(path,0)\n",
    "                    img = cv2.resize(img, resolution)\n",
    "                    if img is not None:\n",
    "                        images[filename] = img\n",
    "            return images\n",
    "        \n",
    "        def sift_dictionary(images: dict) -> list:\n",
    "            \"\"\"Create a dictionary of descriptors with SIFT.\"\"\"\n",
    "            sift = cv2.SIFT_create()\n",
    "            visual_dictionary = []\n",
    "            descriptors_by_image = {}\n",
    "            for name, img in images.items():\n",
    "                kp, des = sift.detectAndCompute(img, None)\n",
    "                # print(f'image {name} has {len(des)} descriptors')\n",
    "                visual_dictionary.extend(des)\n",
    "                descriptors_by_image[name] = des\n",
    "            return visual_dictionary, descriptors_by_image\n",
    "        \n",
    "        def kmeans_visual_vocabulary(k: int, visual_dictionary: list) -> tuple:\n",
    "            \"\"\"Create a vocabulary with k-means quantization.\"\"\"\n",
    "            kmeans = KMeans(n_init=10, n_clusters=64)\n",
    "            kmeans.fit(visual_dictionary)\n",
    "            visual_words = kmeans.cluster_centers_\n",
    "            word_classifier = lambda x: kmeans.predict(np.array(x, dtype='float')) \n",
    "            return visual_words, word_classifier\n",
    "        \n",
    "        def get_words_by_image(descriptors_by_image: dict, word_classifier) -> dict:\n",
    "            \"\"\"Get the visual words in each image by using kmeans predictor.\"\"\"\n",
    "            words_by_image = {}\n",
    "            for name, descriptors in descriptors_by_image.items():\n",
    "                words_by_image[name] = word_classifier(descriptors)\n",
    "            return words_by_image\n",
    "        \n",
    "        def get_global_descriptor_by_image(words_by_image: dict, vocabulary_size: int) -> Tuple[dict, np.array]:\n",
    "            \"\"\"Create a histogram of visual words for each image\"\"\"\n",
    "            global_descriptor_by_image = {}\n",
    "            for name, words in words_by_image.items():\n",
    "                global_descriptor_by_image[name] = np.array(\n",
    "                    np.histogram(words, range=(-.5,vocabulary_size+.5), bins=vocabulary_size)[0],\n",
    "                dtype='float32')\n",
    "\n",
    "            # global_descriptor_by_image to array of descriptors\n",
    "            global_descriptors = np.zeros((len(self.images), vocabulary_size), \n",
    "                                          dtype=global_descriptor_by_image[list(global_descriptor_by_image.keys())[0]].dtype)\n",
    "            i = 0\n",
    "            for name, global_descriptor in global_descriptor_by_image.items():\n",
    "                global_descriptors[i, :] = global_descriptor_by_image[name]\n",
    "                i += 1\n",
    "\n",
    "            return global_descriptor_by_image, global_descriptors\n",
    "        \n",
    "        # Processing\n",
    "        print('Loading images...')        \n",
    "        self.images = load_images_from_folder(folder_path, self.working_resolution)\n",
    "        print(f'{len(self.images)} images were loaded')\n",
    "\n",
    "        print('Extracting local descriptors from the images...')   \n",
    "        self.visual_dictionary, self.descriptors_by_image = sift_dictionary(self.images)\n",
    "        print(f'The visual dictionary has {len(self.visual_dictionary)} descriptors')\n",
    "\n",
    "        print('Clustering local descriptors...')\n",
    "        self.visual_words, self.word_classifier = kmeans_visual_vocabulary(self.vocabulary_size, self.visual_dictionary)\n",
    "        print(f'The visual vocabulary has {len(self.visual_words)} visual words')\n",
    "\n",
    "        print('Estracting visual words from the image local descriptors...')\n",
    "        self.words_by_image = get_words_by_image(self.descriptors_by_image, self.word_classifier)\n",
    "        print('The visual words of each image are ready.')\n",
    "\n",
    "        print(\"Computing a global descriptor for each image...\")\n",
    "        self.global_descriptor_by_image, self.global_descriptors = get_global_descriptor_by_image(self.words_by_image, self.vocabulary_size)\n",
    "        print(\"The global descriptors of each image are ready.\")\n",
    "\n",
    "    def retrieve(self, query_image_name: str, result_size: int = 3):\n",
    "        # Create a matcher\n",
    "        bf = cv2.FlannBasedMatcher()\n",
    "\n",
    "        # Match descriptors\n",
    "        matches = bf.knnMatch(self.global_descriptor_by_image[query_image_name].reshape((1, -1)), \n",
    "                              self.global_descriptors, k=result_size)[0]\n",
    "        matches_idx = [match.trainIdx for match in matches]\n",
    "        print(matches_idx)\n",
    "        matches_names = [list(self.images.keys())[i] for i in matches_idx]\n",
    "        print(matches_names)\n",
    "\n",
    "        for i in range(result_size):\n",
    "            name = matches_names[i]\n",
    "            cv2.imshow(f'Query result: {name} - Distance: {matches[i].distance}', cv2.resize(cv2.imread(name), working_resolution))\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def display_images(self):\n",
    "        if self.images is not None:\n",
    "            cv2.namedWindow('image', cv2.WINDOW_GUI_EXPANDED)\n",
    "            for filename in self.images.keys():\n",
    "                cv2.imshow('image', self.images[filename])\n",
    "                cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        else:\n",
    "            print('Images not loaded, use .fit()')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n",
      "28 images were loaded\n",
      "Extracting local descriptors from the images...\n",
      "The visual dictionary has 37999 descriptors\n",
      "Clustering local descriptors...\n",
      "The visual vocabulary has 64 visual words\n",
      "Estracting visual words from the image local descriptors...\n",
      "The visual words of each image are ready.\n",
      "Computing a global descriptor for each image...\n",
      "The global descriptors of each image are ready.\n"
     ]
    }
   ],
   "source": [
    "ir = ImageRetriever()\n",
    "\n",
    "ir.fit(path_images)\n",
    "# ir.display_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 9, 11, 12, 8, 6, 13, 10]\n",
      "['IMG_20220203_152013349.jpg', 'IMG_20220214_144907525.jpg', 'IMG_20220216_143433424.jpg', 'IMG_20220216_145949270.jpg', 'IMG_20220214_134233140.jpg', 'IMG_20220214_124603956.jpg', 'IMG_20220216_171549908.jpg', 'IMG_20220215_144642554.jpg']\n"
     ]
    }
   ],
   "source": [
    "ir.retrieve('IMG_20220203_152013349.jpg', result_size=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images massively\n",
    "def load_images_from_folder(folder: str, resolution: list) -> list:\n",
    "    images = {}\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.split('.')[-1] == 'jpg':\n",
    "            path = os.path.join(folder, filename)\n",
    "            img = cv2.imread(path,0)\n",
    "            img = cv2.resize(img, resolution)\n",
    "            if img is not None:\n",
    "                images[filename] = img\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_images_from_folder(path_images, working_resolution)\n",
    "cv2.namedWindow('image', cv2.WINDOW_GUI_EXPANDED)\n",
    "for filename in images.keys():\n",
    "    cv2.imshow('image', images[filename])\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract global descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dictionary of descriptors with SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_dictionary(images: dict) -> list:\n",
    "    sift = cv2.SIFT_create()\n",
    "    visual_dictionary = []\n",
    "    descriptors_by_image = {}\n",
    "    for name, img in images.items():\n",
    "        kp, des = sift.detectAndCompute(img, None)\n",
    "        print(f'image {name} has {len(des)} descriptors')\n",
    "        visual_dictionary.extend(des)\n",
    "        descriptors_by_image[name] = des\n",
    "    return visual_dictionary, descriptors_by_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image im1.jpg has 2920 descriptors\n",
      "image im2.jpg has 183 descriptors\n",
      "image im3.jpg has 504 descriptors\n",
      "image IMG_20220203_152013349.jpg has 1545 descriptors\n",
      "image IMG_20220203_155830590.jpg has 986 descriptors\n",
      "image IMG_20220207_131922403.jpg has 656 descriptors\n",
      "image IMG_20220214_124603956.jpg has 1594 descriptors\n",
      "image IMG_20220214_133333313.jpg has 1986 descriptors\n",
      "image IMG_20220214_134233140.jpg has 1742 descriptors\n",
      "image IMG_20220214_144907525.jpg has 1572 descriptors\n",
      "image IMG_20220215_144642554.jpg has 1961 descriptors\n",
      "image IMG_20220216_143433424.jpg has 1739 descriptors\n",
      "image IMG_20220216_145949270.jpg has 1467 descriptors\n",
      "image IMG_20220216_171549908.jpg has 1826 descriptors\n",
      "image IMG_20220218_153152657.jpg has 1647 descriptors\n",
      "image IMG_20220330_143611689.jpg has 1531 descriptors\n",
      "image IMG_20220330_143707804.jpg has 495 descriptors\n",
      "image IMG_20220330_143722955.jpg has 1988 descriptors\n",
      "image IMG_20221013_095154171.jpg has 926 descriptors\n",
      "image IMG_20221013_095209402.jpg has 605 descriptors\n",
      "image IMG_20231202_090817_1068008126061804504.jpg has 1899 descriptors\n",
      "image IMG_20231202_090912_5907586446690967229.jpg has 2119 descriptors\n",
      "image IMG_20231217_222533482.jpg has 1216 descriptors\n",
      "image IMG_20231217_222547646_HDR.jpg has 1359 descriptors\n",
      "image IMG_20231217_222602428_HDR.jpg has 814 descriptors\n",
      "image IMG_20231217_222618223.jpg has 977 descriptors\n",
      "image spy1.jpg has 895 descriptors\n",
      "image spy2.jpg has 847 descriptors\n",
      "The visual dictionary has 37999 descriptors\n"
     ]
    }
   ],
   "source": [
    "visual_dictionary, descriptors_by_image = sift_dictionary(images)\n",
    "print(f'The visual dictionary has {len(visual_dictionary)} descriptors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a vocabulary with k-means quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_visual_vocabulary(k: int, visual_dictionary: List) -> tuple:\n",
    "    kmeans = KMeans(n_init=10, n_clusters=64)\n",
    "    kmeans.fit(visual_dictionary)\n",
    "    visual_words = kmeans.cluster_centers_\n",
    "    word_classifier = lambda x: kmeans.predict(np.array(x, dtype='float')) \n",
    "    return visual_words, word_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The visual vocabulary has 64 visual words\n"
     ]
    }
   ],
   "source": [
    "visual_words, word_classifier = kmeans_visual_vocabulary(vocabulary_size, visual_dictionary)\n",
    "print(f'The visual vocabulary has {len(visual_words)} visual words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the image global descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the visual words in each image by using kmeans predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_by_image(descriptors_by_image: dict, word_classifier) -> dict:\n",
    "    words_by_image = {}\n",
    "    for name, descriptors in descriptors_by_image.items():\n",
    "        words_by_image[name] = word_classifier(descriptors)\n",
    "    return words_by_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2920, 128)\n",
      "(2920,)\n"
     ]
    }
   ],
   "source": [
    "words_by_image = get_words_by_image(descriptors_by_image, word_classifier)\n",
    "\n",
    "print(descriptors_by_image[list(descriptors_by_image.keys())[0]].shape)\n",
    "print(words_by_image[list(descriptors_by_image.keys())[0]].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a histogram of visual words for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_descriptor_by_image(words_by_image: dict, vocabulary_size: int) -> dict:\n",
    "    global_descriptor_by_image = {}\n",
    "    for name, words in words_by_image.items():\n",
    "        global_descriptor_by_image[name] = np.array(\n",
    "            np.histogram(words, range=(-.5,vocabulary_size+.5), bins=vocabulary_size)[0],\n",
    "        dtype='float32')\n",
    "    return global_descriptor_by_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 49.  19.  34.  47.  46.  49.  35.  34.  30.   1.  44.  68.  42.  41.\n",
      "  41.  54.  25.  56.  79.  24.  62.  25.  20.  93.  35.  74.  93.  34.\n",
      " 125.  21. 116.  77.  61.  79.  72.  45.  67.  32. 103.  23.  41.  35.\n",
      "  47.  26.  50.  43.  33.  34.  19.  33.  49.  22.  71.  30.  58.  66.\n",
      "  11.  44.   9.  39.  23.  46.  16.   0.]\n"
     ]
    }
   ],
   "source": [
    "global_descriptor_by_image = get_global_descriptor_by_image(words_by_image, vocabulary_size)\n",
    "\n",
    "print(global_descriptor_by_image[list(global_descriptor_by_image.keys())[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the query image and result size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_image_name = list(images.keys())[3]\n",
    "query_image_name = 'IMG_20220203_152013349.jpg'\n",
    "result_size = 4\n",
    "\n",
    "win_name = f\"Query image: {query_image_name}\"\n",
    "cv2.namedWindow(win_name)\n",
    "cv2.imshow(win_name, images[query_image_name])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 9, 8, 11]\n",
      "['IMG_20220203_152013349.jpg', 'IMG_20220214_144907525.jpg', 'IMG_20220214_134233140.jpg', 'IMG_20220216_143433424.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Create a matcher\n",
    "bf = cv2.FlannBasedMatcher()\n",
    "\n",
    "# global_descriptor_by_image to array of descriptors\n",
    "global_descriptors = np.zeros((len(images), vocabulary_size), \n",
    "                              dtype=global_descriptor_by_image[query_image_name].dtype)\n",
    "i = 0\n",
    "for name, global_descriptor in global_descriptor_by_image.items():\n",
    "    global_descriptors[i, :] = global_descriptor_by_image[name]\n",
    "    i += 1\n",
    "\n",
    "# Match descriptors\n",
    "matches = bf.knnMatch(global_descriptor_by_image[query_image_name].reshape((1, -1)), global_descriptors, k=result_size)[0]\n",
    "matches_idx = [match.trainIdx for match in matches]\n",
    "print(matches_idx)\n",
    "matches_names = [list(images.keys())[i] for i in matches_idx]\n",
    "print(matches_names)\n",
    "\n",
    "\n",
    "for i in range(result_size):\n",
    "    name = matches_names[i]\n",
    "    cv2.imshow(f'Query result: {name} - Distance: {matches[i].distance}', cv2.resize(cv2.imread(name), working_resolution))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
