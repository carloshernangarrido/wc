{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import os\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_images = r'C:\\Fotos y videos\\test bovw'\n",
    "path_images = r'C:\\TRABAJO\\Willdom\\Sr Machine Learning Engineer\\Challenge'\n",
    "working_resolution = [512,512]\n",
    "vocabulary_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images massively\n",
    "def load_images_from_folder(folder: str, resolution: list) -> list:\n",
    "    images = {}\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.split('.')[-1] == 'jpg':\n",
    "            path = os.path.join(folder, filename)\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, resolution)\n",
    "            if img is not None:\n",
    "                images[filename] = img\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_images_from_folder(path_images, working_resolution)\n",
    "cv2.namedWindow('image', cv2.WINDOW_GUI_EXPANDED)\n",
    "for filename in images.keys():\n",
    "    cv2.imshow('image', images[filename])\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract global descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dictionary of descriptors with SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_dictionary(images: dict) -> list:\n",
    "    sift = cv2.SIFT_create()\n",
    "    visual_dictionary = []\n",
    "    descriptors_by_image = {}\n",
    "    for name, img in images.items():\n",
    "        kp, des = sift.detectAndCompute(img, None)\n",
    "        print(f'image {name} has {len(des)} descriptors')\n",
    "        visual_dictionary.extend(des)\n",
    "        descriptors_by_image[name] = des\n",
    "    return visual_dictionary, descriptors_by_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image im1.jpg has 2920 descriptors\n",
      "image im2.jpg has 183 descriptors\n",
      "image im3.jpg has 504 descriptors\n",
      "image IMG_20220203_152013349.jpg has 1545 descriptors\n",
      "image IMG_20220203_155830590.jpg has 986 descriptors\n",
      "image IMG_20220207_131922403.jpg has 656 descriptors\n",
      "image IMG_20220214_124603956.jpg has 1594 descriptors\n",
      "image IMG_20220214_133333313.jpg has 1986 descriptors\n",
      "image IMG_20220214_134233140.jpg has 1742 descriptors\n",
      "image IMG_20220214_144907525.jpg has 1572 descriptors\n",
      "image IMG_20220215_144642554.jpg has 1961 descriptors\n",
      "image IMG_20220216_143433424.jpg has 1739 descriptors\n",
      "image IMG_20220216_145949270.jpg has 1467 descriptors\n",
      "image IMG_20220216_171549908.jpg has 1826 descriptors\n",
      "image IMG_20220218_153152657.jpg has 1647 descriptors\n",
      "image IMG_20220330_143611689.jpg has 1531 descriptors\n",
      "image IMG_20220330_143707804.jpg has 495 descriptors\n",
      "image IMG_20220330_143722955.jpg has 1988 descriptors\n",
      "image IMG_20221013_095154171.jpg has 926 descriptors\n",
      "image IMG_20221013_095209402.jpg has 605 descriptors\n",
      "image IMG_20231202_090817_1068008126061804504.jpg has 1899 descriptors\n",
      "image IMG_20231202_090912_5907586446690967229.jpg has 2119 descriptors\n",
      "image IMG_20231217_222533482.jpg has 1216 descriptors\n",
      "image IMG_20231217_222547646_HDR.jpg has 1359 descriptors\n",
      "image IMG_20231217_222602428_HDR.jpg has 814 descriptors\n",
      "image IMG_20231217_222618223.jpg has 977 descriptors\n",
      "image spy1.jpg has 895 descriptors\n",
      "image spy2.jpg has 847 descriptors\n",
      "The visual dictionary has 37999 descriptors\n"
     ]
    }
   ],
   "source": [
    "visual_dictionary, descriptors_by_image = sift_dictionary(images)\n",
    "print(f'The visual dictionary has {len(visual_dictionary)} descriptors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a vocabulary with k-means quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_visual_vocabulary(k: int, visual_dictionary: List) -> tuple:\n",
    "    kmeans = KMeans(n_init=10, n_clusters=64)\n",
    "    kmeans.fit(visual_dictionary)\n",
    "    visual_words = kmeans.cluster_centers_\n",
    "    word_classifier = lambda x: kmeans.predict(np.array(x, dtype='float')) \n",
    "    return visual_words, word_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The visual vocabulary has 64 visual words\n"
     ]
    }
   ],
   "source": [
    "visual_words, word_classifier = kmeans_visual_vocabulary(vocabulary_size, visual_dictionary)\n",
    "print(f'The visual vocabulary has {len(visual_words)} visual words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the image global descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the visual words in each image by using kmeans predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_by_image(descriptors_by_image: dict, word_classifier) -> dict:\n",
    "    words_by_image = {}\n",
    "    for name, descriptors in descriptors_by_image.items():\n",
    "        words_by_image[name] = word_classifier(descriptors)\n",
    "    return words_by_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2920, 128)\n",
      "(2920,)\n"
     ]
    }
   ],
   "source": [
    "words_by_image = get_words_by_image(descriptors_by_image, word_classifier)\n",
    "\n",
    "print(descriptors_by_image[list(descriptors_by_image.keys())[0]].shape)\n",
    "print(words_by_image[list(descriptors_by_image.keys())[0]].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a histogram of visual words for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_descriptor_by_image(words_by_image: dict, vocabulary_size: int) -> dict:\n",
    "    global_descriptor_by_image = {}\n",
    "    for name, words in words_by_image.items():\n",
    "        global_descriptor_by_image[name] = np.array(\n",
    "            np.histogram(words, range=(-.5,vocabulary_size+.5), bins=vocabulary_size)[0],\n",
    "        dtype='float32')\n",
    "    return global_descriptor_by_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 37.  10.  22.  53.  43.  23.  22.  40.  44.  38.  34.  22.  26.  15.\n",
      "  69.  18.   0.  23.  69.  41.  60.  30.  41.  39.  92.  31.  39.  42.\n",
      "  23.  39.  45. 103. 107.  69.  21.  28. 133.  20.  54.  21.  49.  52.\n",
      "  30.  32.  29.  22.  49.  83.  30.  89.  21.  43. 110.  43.  77.  63.\n",
      "  31.  68.  74.  82.  45.  79.  33.   0.]\n"
     ]
    }
   ],
   "source": [
    "global_descriptor_by_image = get_global_descriptor_by_image(words_by_image, vocabulary_size)\n",
    "\n",
    "print(global_descriptor_by_image[list(global_descriptor_by_image.keys())[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the query image and result size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_image_name = list(images.keys())[3]\n",
    "query_image_name = 'IMG_20220203_152013349.jpg'\n",
    "result_size = 4\n",
    "\n",
    "win_name = f\"Query image: {query_image_name}\"\n",
    "cv2.namedWindow(win_name)\n",
    "cv2.imshow(win_name, images[query_image_name])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 9, 8, 11]\n",
      "['IMG_20220203_152013349.jpg', 'IMG_20220214_144907525.jpg', 'IMG_20220214_134233140.jpg', 'IMG_20220216_143433424.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Create a matcher\n",
    "bf = cv2.FlannBasedMatcher()\n",
    "\n",
    "# global_descriptor_by_image to array of descriptors\n",
    "global_descriptors = np.zeros((len(images), vocabulary_size), \n",
    "                              dtype=global_descriptor_by_image[query_image_name].dtype)\n",
    "i = 0\n",
    "for name, global_descriptor in global_descriptor_by_image.items():\n",
    "    global_descriptors[i, :] = global_descriptor_by_image[name]\n",
    "    i += 1\n",
    "\n",
    "# Match descriptors\n",
    "matches = bf.knnMatch(global_descriptor_by_image[query_image_name].reshape((1, -1)), global_descriptors, k=result_size)[0]\n",
    "matches_idx = [match.trainIdx for match in matches]\n",
    "print(matches_idx)\n",
    "matches_names = [list(images.keys())[i] for i in matches_idx]\n",
    "print(matches_names)\n",
    "\n",
    "\n",
    "for i in range(result_size):\n",
    "    name = matches_names[i]\n",
    "    cv2.imshow(f'Query result: {name} - Distance: {matches[i].distance}', cv2.resize(cv2.imread(name), working_resolution))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
